import asyncio
import html
import os
import re
from urllib.parse import urlsplit

import requests
from aiogram import types, Router, F
from aiogram.types import FSInputFile
from aiogram.utils.media_group import MediaGroupBuilder
from aiogram.utils.exceptions import FloodWait
import messages as bm
from config import OUTPUT_DIR, CHANNEL_IDtwiter
from main import bot, db, send_analytics

MAX_FILE_SIZE = 500 * 1024 * 1024
MAX_RETRIES = 3  # Ø£Ù‚ØµÙ‰ Ø¹Ø¯Ø¯ Ù…Ù† Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø§Øª Ø¹Ù†Ø¯ Ø§Ù„Ø­Ø¸Ø±

router = Router()
album_accumulator = {}
chat_queues = {}
chat_workers = {}

# ØªØ­Ø¯ÙŠØ¯ Ø¹Ø¯Ø¯ Ø§Ù„ØªØºØ±ÙŠØ¯Ø§Øª Ø§Ù„ØªÙŠ ÙŠÙ…ÙƒÙ† Ù…Ø¹Ø§Ù„Ø¬ØªÙ‡Ø§ ÙÙŠ Ù†ÙØ³ Ø§Ù„ÙˆÙ‚Øª
CONCURRENT_TWEETS_SEMAPHORE = asyncio.Semaphore(3)

def extract_tweet_ids(text):
    """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…Ø¹Ø±ÙØ§Øª Ø§Ù„ØªØºØ±ÙŠØ¯Ø§Øª Ù…Ù† Ø§Ù„Ù†Øµ"""
    unshortened_links = ''
    for link in re.findall(r't\.co\/[a-zA-Z0-9]+', text):
        try:
            unshortened_link = requests.get('https://' + link).url
            unshortened_links += '\n' + unshortened_link
        except:
            pass

    tweet_ids = re.findall(r"(?:twitter|x)\.com/.{1,15}/(?:web|status(?:es)?)/([0-9]{1,20})", text + unshortened_links)
    return list(dict.fromkeys(tweet_ids)) if tweet_ids else None

async def scrape_media_with_retry(tweet_id):
    """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„ÙˆØ³Ø§Ø¦Ø· Ù…Ø¹ Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø©"""
    async with CONCURRENT_TWEETS_SEMAPHORE:
        return await asyncio.to_thread(scrape_media, tweet_id)

def scrape_media(tweet_id):
    """Ø§Ù„Ø¯Ø§Ù„Ø© Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© Ù„Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª (ØªØ³ØªØ®Ø¯Ù… requests)"""
    r = requests.get(f'https://api.vxtwitter.com/Twitter/status/{tweet_id}')
    r.raise_for_status()
    try:
        return r.json()
    except requests.exceptions.JSONDecodeError:
        if match := re.search(r'<meta content="(.*?)" property="og:description" />', r.text):
            raise Exception(f'API returned error: {html.unescape(match.group(1))}')
        raise

async def download_media(media_url, file_path):
    """ØªÙ†Ø²ÙŠÙ„ Ø§Ù„ÙˆØ³Ø§Ø¦Ø· Ù…Ø¹ Ø§Ù„ØªØ­ÙƒÙ… ÙÙŠ Ø­Ø¬Ù… Ø§Ù„Ù…Ù„Ù"""
    response = requests.get(media_url, stream=True)
    response.raise_for_status()
    
    if int(response.headers.get('content-length', 0)) > MAX_FILE_SIZE:
        raise ValueError("File size exceeds maximum allowed limit")
    
    with open(file_path, 'wb') as file:
        for chunk in response.iter_content(chunk_size=8192):
            file.write(chunk)

async def send_media_group_with_retry(message, media_group, business_id):
    """Ø¥Ø±Ø³Ø§Ù„ Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„ÙˆØ³Ø§Ø¦Ø· Ù…Ø¹ Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø©"""
    retry_count = 0
    while retry_count < MAX_RETRIES:
        try:
            await message.answer_media_group(media_group)
            await asyncio.sleep(5)  # ØªØ£Ø®ÙŠØ± Ø¨Ø¹Ø¯ ÙƒÙ„ Ø¥Ø±Ø³Ø§Ù„
            return True
        except FloodWait as e:
            print(f"FloodWait: Retry {retry_count+1}/{MAX_RETRIES} after {e.timeout}s")
            await asyncio.sleep(e.timeout)
            retry_count += 1
        except Exception as e:
            print(f"Error sending media: {e}")
            break
    return False

async def reply_media(message, tweet_id, tweet_media, bot_url, business_id):
    """Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ÙˆØ³Ø§Ø¦Ø· Ù…Ø¹ Ø§Ù„ØªØ­ÙƒÙ… ÙÙŠ Ø§Ù„ØªØ¯ÙÙ‚"""
    await send_analytics(user_id=message.from_user.id, chat_type=message.chat.type, action_name="twitter")

    tweet_dir = f"{OUTPUT_DIR}/{tweet_id}"
    post_caption = tweet_media["text"]
    user_captions = await db.get_user_captions(message.from_user.id)

    if not os.path.exists(tweet_dir):
        os.makedirs(tweet_dir)

    key = message.chat.id
    if key not in album_accumulator:
        album_accumulator[key] = {"image": [], "video": []}

    try:
        # ØªÙ†Ø²ÙŠÙ„ ÙˆØªØ¬Ù…ÙŠØ¹ Ø§Ù„ÙˆØ³Ø§Ø¦Ø·
        for media in tweet_media['media_extended']:
            media_url = media['url']
            media_type = media['type']
            file_name = os.path.join(tweet_dir, os.path.basename(urlsplit(media_url).path))
            await download_media(media_url, file_name)
            
            if media_type == 'image':
                album_accumulator[key]["image"].append((file_name, media_type, tweet_dir))
            elif media_type in ['video', 'gif']:
                album_accumulator[key]["video"].append((file_name, media_type, tweet_dir))

        # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØ±
        while len(album_accumulator[key]["image"]) >= 5:
            media_group = MediaGroupBuilder(caption=bm.captions(user_captions, post_caption, bot_url))
            batch = album_accumulator[key]["image"][:5]
            
            for file_path, _, _ in batch:
                media_group.add_photo(media=FSInputFile(file_path))
                
            if not await send_media_group_with_retry(message, media_group.build(), business_id):
                raise Exception("Failed to send media group after retries")
            
            # ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…Ø±Ø³Ù„Ø©
            for file_path, _, dir_path in batch:
                if os.path.exists(file_path): os.remove(file_path)
                if os.path.exists(dir_path) and not os.listdir(dir_path): os.rmdir(dir_path)
                
            album_accumulator[key]["image"] = album_accumulator[key]["image"][5:]

        # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ÙÙŠØ¯ÙŠÙˆÙ‡Ø§Øª
        while len(album_accumulator[key]["video"]) >= 5:
            media_group = MediaGroupBuilder(caption=bm.captions(user_captions, post_caption, bot_url))
            batch = album_accumulator[key]["video"][:5]
            
            for file_path, _, _ in batch:
                media_group.add_video(media=FSInputFile(file_path))
                
            if not await send_media_group_with_retry(message, media_group.build(), business_id):
                raise Exception("Failed to send media group after retries")
            
            # ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…Ø±Ø³Ù„Ø©
            for file_path, _, dir_path in batch:
                if os.path.exists(file_path): os.remove(file_path)
                if os.path.exists(dir_path) and not os.listdir(dir_path): os.rmdir(dir_path)
                
            album_accumulator[key]["video"] = album_accumulator[key]["video"][5:]

    except Exception as e:
        print(f"Error in reply_media: {e}")
        if business_id is None:
            await message.react([types.ReactionTypeEmoji(emoji="ğŸ‘")])
        await message.answer("Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© âš ï¸")

async def process_chat_queue(chat_id):
    """Ù…Ø¹Ø§Ù„Ø¬Ø© Ù‚ÙˆØ§Ø¦Ù… Ø§Ù„Ø§Ù†ØªØ¸Ø§Ø± Ù…Ø¹ Ø§Ù„ØªØ­ÙƒÙ… ÙÙŠ Ø§Ù„ØªØ¯ÙÙ‚"""
    while True:
        message = await chat_queues[chat_id].get()
        try:
            business_id = message.business_connection_id
            bot_url = f"t.me/{(await bot.get_me()).username}"
            
            if tweet_ids := extract_tweet_ids(message.text):
                if business_id is None:
                    await bot.send_chat_action(message.chat.id, "typing")
                
                for tweet_id in tweet_ids:
                    try:
                        media = await scrape_media_with_retry(tweet_id)
                        await reply_media(message, tweet_id, media, bot_url, business_id)
                        await asyncio.sleep(3)  # ØªØ£Ø®ÙŠØ± Ø¨ÙŠÙ† Ø§Ù„ØªØºØ±ÙŠØ¯Ø§Øª
                    except Exception as e:
                        print(f"Error processing tweet {tweet_id}: {e}")
                
                await asyncio.sleep(2)  # ØªØ£Ø®ÙŠØ± Ù†Ù‡Ø§Ø¦ÙŠ
                try:
                    await message.delete()
                except Exception as e:
                    print(f"Error deleting message: {e}")
            else:
                if business_id is None:
                    await message.react([types.ReactionTypeEmoji(emoji="ğŸ‘")])
                await message.answer("Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø±ÙˆØ§Ø¨Ø· ØµØ§Ù„Ø­Ø© âŒ")
                
        finally:
            chat_queues[chat_id].task_done()
            await asyncio.sleep(1)  # ØªØ£Ø®ÙŠØ± Ø¨ÙŠÙ† Ø§Ù„Ø±Ø³Ø§Ø¦Ù„

@router.message(F.text.regexp(r"(https?://(www\.)?(twitter|x)\.com/\S+|https?://t\.co/\S+)"))
@router.business_message(F.text.regexp(r"(https?://(www\.)?(twitter|x)\.com/\S+|https?://t\.co/\S+)"))
async def handle_tweet_links(message):
    """Ø¥Ø¯Ø§Ø±Ø© Ù‚ÙˆØ§Ø¦Ù… Ø§Ù„Ø§Ù†ØªØ¸Ø§Ø±"""
    chat_id = message.chat.id
    if chat_id not in chat_queues:
        chat_queues[chat_id] = asyncio.Queue()
        chat_workers[chat_id] = asyncio.create_task(process_chat_queue(chat_id))
    await chat_queues[chat_id].put(message)
