import asyncio
import html
import os
import re
from urllib.parse import urlsplit

import requests
from aiogram import types, Router, F
from aiogram.types import FSInputFile
from aiogram.utils.media_group import MediaGroupBuilder

import messages as bm
from config import OUTPUT_DIR, CHANNEL_IDtwiter
from main import bot, db, send_analytics

MAX_FILE_SIZE = 500 * 1024 * 1024
MAX_CONCURRENT_TWEETS = 3  # âœ… Ø¹Ø¯Ø¯ Ø§Ù„ØªØºØ±ÙŠØ¯Ø§Øª Ø§Ù„ØªÙŠ ØªÙØ¹Ø§Ù„Ø¬ ÙÙŠ Ù†ÙØ³ Ø§Ù„ÙˆÙ‚Øª
PROCESSING_DELAY = 5  # âœ… ØªØ£Ø®ÙŠØ± Ø¨ÙŠÙ† ÙƒÙ„ ØªØºØ±ÙŠØ¯Ø© Ù„Ù…Ù†Ø¹ Ø§Ù„ÙÙ„ÙˆØ¯

router = Router()
album_accumulator_photos = {}
album_accumulator_videos = {}

tweet_queue = asyncio.Queue()  # âœ… Ù‚Ø§Ø¦Ù…Ø© Ø§Ù†ØªØ¸Ø§Ø± Ù„Ù„ØªØºØ±ÙŠØ¯Ø§Øª


def extract_tweet_ids(text):
    """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…Ø¹Ø±ÙØ§Øª Ø§Ù„ØªØºØ±ÙŠØ¯Ø§Øª Ù…Ù† Ø§Ù„Ù†Øµ."""
    unshortened_links = ''
    for link in re.findall(r't\.co\/[a-zA-Z0-9]+', text):
        try:
            unshortened_link = requests.get('https://' + link).url
            unshortened_links += '\n' + unshortened_link
        except:
            pass

    tweet_ids = re.findall(r"(?:twitter|x)\.com/.{1,15}/(?:web|status(?:es)?)/([0-9]{1,20})", text + unshortened_links)
    return list(dict.fromkeys(tweet_ids)) if tweet_ids else None


async def process_tweets():
    """Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØªØºØ±ÙŠØ¯Ø§Øª ØªØ¯Ø±ÙŠØ¬ÙŠÙ‹Ø§ Ù…Ù† Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø§Ù†ØªØ¸Ø§Ø±."""
    while True:
        message, tweet_id, bot_url, business_id = await tweet_queue.get()
        try:
            media = scrape_media(tweet_id)
            await reply_media(message, tweet_id, media, bot_url, business_id)
        except Exception as e:
            print(f"âŒ Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØªØºØ±ÙŠØ¯Ø© {tweet_id}: {e}")

        await asyncio.sleep(PROCESSING_DELAY)  # âœ… ØªØ£Ø®ÙŠØ± Ø¨ÙŠÙ† ÙƒÙ„ ØªØºØ±ÙŠØ¯Ø© Ù„ØªÙ‚Ù„ÙŠÙ„ Ø§Ù„ÙÙ„ÙˆØ¯


def scrape_media(tweet_id):
    """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„ÙˆØ³Ø§Ø¦Ø· Ù…Ù† Ø§Ù„ØªØºØ±ÙŠØ¯Ø©."""
    r = requests.get(f'https://api.vxtwitter.com/Twitter/status/{tweet_id}')
    r.raise_for_status()
    try:
        return r.json()
    except requests.exceptions.JSONDecodeError:
        if match := re.search(r'<meta content="(.*?)" property="og:description" />', r.text):
            raise Exception(f'API returned error: {html.unescape(match.group(1))}')
        raise


async def reply_media(message, tweet_id, tweet_media, bot_url, business_id):
    """ØªÙ†Ø²ÙŠÙ„ Ø§Ù„ÙˆØ³Ø§Ø¦Ø· ÙˆØ¥Ø±Ø³Ø§Ù„Ù‡Ø§ Ù„Ù„Ù…Ø³ØªØ®Ø¯Ù…."""
    chat_id = message.chat.id
    tweet_dir = f"{OUTPUT_DIR}/{tweet_id}"
    post_caption = tweet_media["text"]
    user_captions = await db.get_user_captions(message.from_user.id)

    if not os.path.exists(tweet_dir):
        os.makedirs(tweet_dir)

    downloaded_photos = []
    downloaded_videos = []

    try:
        for media in tweet_media['media_extended']:
            media_url = media['url']
            media_type = media['type']
            file_name = os.path.join(tweet_dir, os.path.basename(urlsplit(media_url).path))
            await download_media(media_url, file_name)

            if media_type == 'image':
                downloaded_photos.append((file_name, media_type, tweet_dir))
            elif media_type in ['video', 'gif']:
                downloaded_videos.append((file_name, media_type, tweet_dir))

        if chat_id not in album_accumulator_photos:
            album_accumulator_photos[chat_id] = []
        if chat_id not in album_accumulator_videos:
            album_accumulator_videos[chat_id] = []

        album_accumulator_photos[chat_id].extend(downloaded_photos)
        album_accumulator_videos[chat_id].extend(downloaded_videos)

    except Exception as e:
        print(e)
        if business_id is None:
            await message.react([types.ReactionTypeEmoji(emoji="ğŸ‘")])
        await message.reply("Ø­Ø¯Ø« Ø®Ø·Ø£ØŒ Ø§Ù„Ø±Ø¬Ø§Ø¡ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ù„Ø§Ø­Ù‚Ù‹Ø§.")


async def download_media(media_url, file_path):
    """ØªÙ†Ø²ÙŠÙ„ Ø§Ù„ÙˆØ³Ø§Ø¦Ø· ÙˆØ­ÙØ¸Ù‡Ø§ Ù…Ø­Ù„ÙŠÙ‹Ø§."""
    response = requests.get(media_url, stream=True)
    response.raise_for_status()
    with open(file_path, 'wb') as file:
        for chunk in response.iter_content(chunk_size=8192):
            file.write(chunk)


@router.message(F.text.regexp(r"(https?://(www\.)?(twitter|x)\.com/\S+|https?://t\.co/\S+)"))
@router.business_message(F.text.regexp(r"(https?://(www\.)?(twitter|x)\.com/\S+|https?://t\.co/\S+)"))
async def handle_tweet_links(message):
    """Ø¥Ø¶Ø§ÙØ© Ø§Ù„ØªØºØ±ÙŠØ¯Ø§Øª Ø¥Ù„Ù‰ Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø§Ù†ØªØ¸Ø§Ø± ÙˆÙ…Ø¹Ø§Ù„Ø¬ØªÙ‡Ø§ ØªØ¯Ø±ÙŠØ¬ÙŠÙ‹Ø§."""
    business_id = message.business_connection_id

    if business_id is None:
        await message.react([types.ReactionTypeEmoji(emoji="ğŸ‘¨â€ğŸ’»")])

    bot_url = f"t.me/{(await bot.get_me()).username}"

    tweet_ids = extract_tweet_ids(message.text)
    if tweet_ids:
        if business_id is None:
            await bot.send_chat_action(message.chat.id, "typing")

        for tweet_id in tweet_ids:
            await tweet_queue.put((message, tweet_id, bot_url, business_id))  # âœ… Ø¥Ø¶Ø§ÙØ© Ø§Ù„ØªØºØ±ÙŠØ¯Ø© Ø¥Ù„Ù‰ Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø§Ù†ØªØ¸Ø§Ø±

        # Ù„Ø§ Ù†Ø­Ø°Ù Ø§Ù„Ø±Ø³Ø§Ø¦Ù„ Ù…Ø¨Ø§Ø´Ø±Ø© Ø¨Ù„ Ù†ØªØ±ÙƒÙ‡Ø§ Ø­ØªÙ‰ ØªØªÙ… Ù…Ø¹Ø§Ù„Ø¬ØªÙ‡Ø§ Ø¨Ø§Ù„ÙƒØ§Ù…Ù„

    else:
        if business_id is None:
            await message.react([types.ReactionTypeEmoji(emoji="ğŸ‘")])
        await message.answer("Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù…Ø¹Ø±ÙØ§Øª ØªØºØ±ÙŠØ¯Ø§Øª ØµØ§Ù„Ø­Ø©.")


async def start_tweet_processor():
    """ØªØ´ØºÙŠÙ„ Ù…Ø¹Ø§Ù„Ø¬ Ø§Ù„ØªØºØ±ÙŠØ¯Ø§Øª ÙÙŠ Ø§Ù„Ø®Ù„ÙÙŠØ©."""
    for _ in range(MAX_CONCURRENT_TWEETS):  # âœ… Ù…Ø¹Ø§Ù„Ø¬Ø© 3 ØªØºØ±ÙŠØ¯Ø§Øª ÙÙ‚Ø· ÙÙŠ Ù†ÙØ³ Ø§Ù„ÙˆÙ‚Øª
        asyncio.create_task(process_tweets())
