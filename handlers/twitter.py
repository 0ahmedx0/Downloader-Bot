import asyncio
import html
import os
import re
from urllib.parse import urlsplit
import requests
import aiohttp # âœ… Ø¥Ø¶Ø§ÙØ© aiohttp Ù„Ù„Ø·Ù„Ø¨Ø§Øª ØºÙŠØ± Ø§Ù„Ù…ØªØ²Ø§Ù…Ù†Ø©

from aiogram import types, Router, F
from aiogram.types import FSInputFile
from aiogram.utils.media_group import MediaGroupBuilder
from aiogram.exceptions import TelegramRetryAfter
from pyrogram import Client as PyroClient # âœ… Pyrogram

import messages as bm
from config import OUTPUT_DIR, CHANNEL_IDtwiter
from main import bot, db, send_analytics # Ø§ÙØªØ±Ø¶ Ø£Ù† Ù‡Ø°Ù‡ Ø§Ù„ÙˆØ­Ø¯Ø§Øª Ù…ØªÙˆÙØ±Ø©

# âœ… Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Pyrogram Ù…Ù† Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ø¨ÙŠØ¦ÙŠØ© (string session)
PYROGRAM_API_ID = int(os.environ.get('ID'))
PYROGRAM_API_HASH = os.environ.get('HASH')
PYROGRAM_SESSION_STRING = os.environ.get('PYRO_SESSION_STRING') # ÙŠØ¬Ø¨ Ø£Ù† ØªÙƒÙˆÙ† string session

MAX_FILE_SIZE = 50 * 1024 * 1024 # Ø­Ø¯ ØªÙ„ÙŠØ¬Ø±Ø§Ù… Ù„Ù„Ù…Ù„Ù Ø¯Ø§Ø®Ù„ Ø§Ù„Ø¨ÙˆØª

router = Router()
album_accumulator = {}
chat_queues = {}
chat_workers = {}

# âœ… Ø¯Ø§Ù„Ø© Ù…Ø³Ø§Ø¹Ø¯Ø© Ù„ÙÙƒ Ø§Ø®ØªØµØ§Ø± Ø§Ù„Ø±ÙˆØ§Ø¨Ø· Ø¨Ø´ÙƒÙ„ ØºÙŠØ± Ù…ØªØ²Ø§Ù…Ù†
async def unshorten_link_async(session, link):
    try:
        # print(f"Attempting to unshorten: https://{link}") # Ù„ØºØ±Ø¶ Ø§Ù„ØªØµØ­ÙŠØ­
        async with session.get('https://' + link, allow_redirects=True, timeout=10) as response:
            final_url = str(response.url)
            # print(f"Unshortened {link} to {final_url}") # Ù„ØºØ±Ø¶ Ø§Ù„ØªØµØ­ÙŠØ­
            return final_url
    except Exception as e:
        print(f"âŒ Error unshortening link {link}: {e}")
        return None

# âœ… ØªØ¹Ø¯ÙŠÙ„ Ø¯Ø§Ù„Ø© Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…Ø¹Ø±ÙØ§Øª Ø§Ù„ØªØºØ±ÙŠØ¯Ø§Øª Ù„ØªÙƒÙˆÙ† ØºÙŠØ± Ù…ØªØ²Ø§Ù…Ù†Ø© ÙˆØªØ³ØªØ®Ø¯Ù… aiohttp
async def extract_tweet_ids_async(text):
    print(f"ğŸ” Starting to extract tweet IDs from text (first 100 chars): {text[:100]}...")
    unshortened_links_tasks = []
    tco_links = re.findall(r't\.co\/[a-zA-Z0-9]+', text)
    unshortened_links_str = ""

    if tco_links:
        print(f"ğŸ”— Found {len(tco_links)} t.co links. Unshortening concurrently...")
        async with aiohttp.ClientSession() as session:
            for link in tco_links:
                unshortened_links_tasks.append(unshorten_link_async(session, link))
            unshortened_links_results = await asyncio.gather(*unshortened_links_tasks)
            unshortened_links_str = '\n'.join([ul for ul in unshortened_links_results if ul])
        print(f"ğŸ”— Finished unshortening {len(tco_links)} t.co links.")
    else:
        print("ğŸ”— No t.co links found.")

    full_text_for_regex = text + '\n' + unshortened_links_str
    tweet_ids = re.findall(r"(?:twitter|x)\.com/.{1,15}/(?:web|status(?:es)?)/([0-9]{1,20})", full_text_for_regex)
    
    unique_tweet_ids = list(dict.fromkeys(tweet_ids)) if tweet_ids else None
    if unique_tweet_ids:
        print(f"âœ… Extracted {len(unique_tweet_ids)} unique tweet IDs: {unique_tweet_ids}")
    else:
        print("â›” No Twitter/X tweet IDs found.")
    return unique_tweet_ids

# ØªØ¨Ù‚Ù‰ Ù‡Ø°Ù‡ Ø§Ù„Ø¯Ø§Ù„Ø© Ù…ØªØ²Ø§Ù…Ù†Ø© Ù„Ø£Ù†Ù‡Ø§ ØªØ³ØªØ®Ø¯Ù… requests (ÙŠÙ…ÙƒÙ† ØªØ­ÙˆÙŠÙ„Ù‡Ø§ Ù„Ù€ aiohttp Ø¥Ø°Ø§ Ø±ØºØ¨Øª)
def scrape_media(tweet_id):
    print(f"ğŸ“¡ Scraping media for tweet ID: {tweet_id} from VxTwitter API.")
    r = requests.get(f'https://api.vxtwitter.com/Twitter/status/{tweet_id}', timeout=10) # Ø£Ø¶Ù timeout
    r.raise_for_status()
    try:
        return r.json()
    except requests.exceptions.JSONDecodeError:
        if match := re.search(r'<meta content="(.*?)" property="og:description" />', r.text):
            error_message = f'API returned error: {html.unescape(match.group(1))}'
            print(f"âŒ VxTwitter API JSON Decode Error for {tweet_id}: {error_message}")
            raise Exception(error_message)
        print(f"âŒ VxTwitter API JSON Decode Error, no specific message found for {tweet_id}")
        raise # Ø£Ø¹Ø¯ Ø±ÙØ¹ Ø§Ù„Ø®Ø·Ø£ Ø§Ù„Ø£ØµÙ„ÙŠ Ø¥Ø°Ø§ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ ÙˆØµÙ

# ØªØ¨Ù‚Ù‰ Ù‡Ø°Ù‡ Ø§Ù„Ø¯Ø§Ù„Ø© Ù…ØªØ²Ø§Ù…Ù†Ø© Ù„Ø£Ù†Ù‡Ø§ ØªØ³ØªØ®Ø¯Ù… requests (ÙŠÙ…ÙƒÙ† ØªØ­ÙˆÙŠÙ„Ù‡Ø§ Ù„Ù€ aiohttp Ø¥Ø°Ø§ Ø±ØºØ¨Øª)
async def download_media(media_url, file_path):
    print(f"â¬‡ï¸ Starting download: {media_url} to {file_path}")
    # ÙŠÙ…ÙƒÙ† Ù‡Ù†Ø§ Ø§Ø³ØªØ®Ø¯Ø§Ù… asyncio.to_thread Ø¥Ø°Ø§ ÙƒÙ†Øª ØªØ±ÙŠØ¯ ØªØ´ØºÙŠÙ„Ù‡Ø§ ÙÙŠ ThreadPoolExecutor Ø¯ÙˆÙ† blocking loop Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ
    # ÙˆÙ„ÙƒÙ† Ù„Ù„ØªÙ†Ø²ÙŠÙ„Ø§Øª Ø§Ù„ÙƒØ¨ÙŠØ±Ø©ØŒ ÙŠÙØ¶Ù„ aiohttp Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ async Ø¨Ø§Ù„ÙƒØ§Ù…Ù„
    response = requests.get(media_url, stream=True, timeout=30) # Ø£Ø¶Ù timeout
    response.raise_for_status()
    with open(file_path, 'wb') as file:
        for chunk in response.iter_content(chunk_size=8192):
            file.write(chunk)
    print(f"âœ… Download complete: {file_path}")

# âœ… Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„ÙƒØ¨ÙŠØ±Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… string session Ù…Ø¹ Pyrogram
async def send_large_file_pyro(chat_id, file_path, caption=None):
    print(f"ğŸ“¤ Sending large file via Pyrogram to chat {chat_id}: {file_path}")
    try:
        async with PyroClient(
            PYROGRAM_SESSION_STRING,
            api_id=PYROGRAM_API_ID,
            api_hash=PYROGRAM_API_HASH,
            in_memory=True
        ) as client:
            await client.send_document(chat_id=chat_id, document=file_path, caption=caption or "")
        print(f"âœ… Large file sent successfully via Pyrogram: {file_path}")
    except Exception as e:
        print(f"âŒ [Pyrogram Error] Failed to send {file_path}: {e}")
        raise # Ø¥Ø¹Ø§Ø¯Ø© Ø±ÙØ¹ Ø§Ù„Ø®Ø·Ø£ Ù„ÙŠØªÙ… Ø§Ù„ØªØ¹Ø§Ù…Ù„ Ù…Ø¹Ù‡ Ø¨ÙˆØ§Ø³Ø·Ø© try/except Ø§Ù„Ø®Ø§Ø±Ø¬ÙŠØ©

async def reply_media(message, tweet_id, tweet_media, bot_url, business_id):
    await send_analytics(user_id=message.from_user.id, chat_type=message.chat.type, action_name="twitter")
    tweet_dir = f"{OUTPUT_DIR}/{tweet_id}"
    post_caption = tweet_media["text"]
    user_captions = await db.get_user_captions(message.from_user.id) # Ø§ÙØªØ±Ø¶ Ø£Ù† Ù‡Ø°Ù‡ Ø§Ù„Ø¯Ø§Ù„Ø© Ù…ÙˆØ¬ÙˆØ¯Ø©
    
    # ØªØ£ÙƒØ¯ Ù…Ù† Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ø¯Ù„ÙŠÙ„ Ù‚Ø¨Ù„ Ø£ÙŠ Ø¹Ù…Ù„ÙŠØ§Øª Ø¹Ù„ÙŠÙ‡
    if not os.path.exists(tweet_dir):
        os.makedirs(tweet_dir)
        print(f"ğŸ“‚ Created directory: {tweet_dir}")

    key = message.chat.id
    if key not in album_accumulator:
        album_accumulator[key] = {"image": [], "video": []}
        print(f"Initializing album_accumulator for chat {key}")

    try:
        # âœ… ØªØ­Ù…ÙŠÙ„ Ø¬Ù…ÙŠØ¹ Ø§Ù„ÙˆØ³Ø§Ø¦Ø· Ø£ÙˆÙ„Ø§Ù‹
        for media in tweet_media['media_extended']:
            media_url = media['url']
            media_type = media['type']
            file_name = os.path.join(tweet_dir, os.path.basename(urlsplit(media_url).path))
            await download_media(media_url, file_name)

            if media_type == 'image':
                album_accumulator[key]["image"].append((file_name, media_type, tweet_dir))
            elif media_type in ['video', 'gif']:
                album_accumulator[key]["video"].append((file_name, media_type, tweet_dir))
        
        print(f"Loaded {len(album_accumulator[key]['image'])} images and {len(album_accumulator[key]['video'])} videos for tweet {tweet_id}")

        # âœ… Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„ØµÙˆØ± ÙÙŠ Ù…Ø¬Ù…ÙˆØ¹Ø§Øª (Ø£Ù„Ø¨ÙˆÙ…Ø§Øª)
        while album_accumulator[key]["image"]:
            # Ø¥Ø±Ø³Ø§Ù„ 5 ØµÙˆØ± ÙƒØ­Ø¯ Ø£Ù‚ØµÙ‰ Ù„ÙƒÙ„ Ù…Ø¬Ù…ÙˆØ¹Ø©
            album_to_send = album_accumulator[key]["image"][:5]
            
            # ÙÙŠ Ø­Ø§Ù„ ÙˆØ¬ÙˆØ¯ ØµÙˆØ±Ø© ÙˆØ§Ø­Ø¯Ø© ÙÙ‚Ø·ØŒ ÙŠØªÙ… Ø¥Ø±Ø³Ø§Ù„Ù‡Ø§ ÙƒØµÙˆØ±Ø© Ø¹Ø§Ø¯ÙŠØ© ÙˆÙ„ÙŠØ³ Ø£Ù„Ø¨ÙˆÙ…
            if len(album_to_send) == 1:
                file_path, _, dir_path = album_to_send[0]
                media_caption = bm.captions(user_captions, post_caption, bot_url) if album_to_send[0] == album_accumulator[key]["image"][0] else None
                print(f"ğŸ–¼ï¸ Sending single image for tweet {tweet_id}: {file_path}")
                while True:
                    try:
                        await message.answer_photo(FSInputFile(file_path), caption=media_caption)
                        break
                    except TelegramRetryAfter as e:
                        print(f"â³ TelegramRetryAfter for image: {e.retry_after} seconds. Retrying...")
                        await asyncio.sleep(e.retry_after)
                
            else: # Ø¥Ø°Ø§ ÙƒØ§Ù† Ù‡Ù†Ø§Ùƒ Ø£ÙƒØ«Ø± Ù…Ù† ØµÙˆØ±Ø© ÙˆØ§Ø­Ø¯Ø©ØŒ ÙŠØªÙ… Ø¥Ø±Ø³Ø§Ù„Ù‡Ø§ ÙƒØ£Ù„Ø¨ÙˆÙ…
                media_group = MediaGroupBuilder(caption=bm.captions(user_captions, post_caption, bot_url))
                for file_path, _, _ in album_to_send:
                    media_group.add_photo(media=FSInputFile(file_path))
                print(f"ğŸ“¸ Sending image album of {len(album_to_send)} photos for tweet {tweet_id}")
                while True:
                    try:
                        await message.answer_media_group(media_group.build())
                        break
                    except TelegramRetryAfter as e:
                        print(f"â³ TelegramRetryAfter for album: {e.retry_after} seconds. Retrying...")
                        await asyncio.sleep(e.retry_after)

            # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ØµÙˆØ± Ø§Ù„Ù…Ø±Ø³Ù„Ø© ÙˆØ­Ø°Ù Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…Ø¤Ù‚ØªØ©
            for file_path, _, dir_path in album_to_send:
                if os.path.exists(file_path):
                    os.remove(file_path)
                    print(f"ğŸ—‘ï¸ Removed file: {file_path}")
                # Ø­Ø°Ù Ø§Ù„Ø¯Ù„ÙŠÙ„ Ø¥Ø°Ø§ Ø£ØµØ¨Ø­ ÙØ§Ø±ØºÙ‹Ø§
                if os.path.exists(dir_path) and not os.listdir(dir_path):
                    os.rmdir(dir_path)
                    print(f"ğŸ—‘ï¸ Removed empty directory: {dir_path}")

            album_accumulator[key]["image"] = album_accumulator[key]["image"][len(album_to_send):]

        # âœ… Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„ÙÙŠØ¯ÙŠÙˆÙ‡Ø§Øª
        for file_path, _, dir_path in album_accumulator[key]["video"]:
            video_caption = bm.captions(user_captions, post_caption, bot_url) # Ø§Ù„ÙƒØ§Ø¨Ø´Ù† Ù„ÙƒÙ„ ÙÙŠØ¯ÙŠÙˆ
            print(f"ğŸ¥ Preparing to send video: {file_path} for tweet {tweet_id}")
            if os.path.getsize(file_path) > MAX_FILE_SIZE:
                try:
                    # ÙŠØ¬Ø¨ Ø£Ù† ÙŠÙƒÙˆÙ† CHANNEL_IDtwiter Ù‡Ùˆ Ù…Ø¹Ø±Ù Ø§Ù„Ø¯Ø±Ø¯Ø´Ø© Ø§Ù„Ø°ÙŠ ÙŠÙ…Ù„Ùƒ Ø§Ù„Ø¬Ù„Ø³Ø© Ù„Ø¥Ø±Ø³Ø§Ù„ Ù…Ù„ÙØ§Øª Pyro
                    # Ø¥Ø°Ø§ Ø£Ø±Ø¯Øª Ø§Ù„Ø¥Ø±Ø³Ø§Ù„ Ù„Ù„Ù…Ø³ØªØ®Ø¯Ù…ØŒ Ø§Ø³ØªØ®Ø¯Ù… message.chat.id
                    await send_large_file_pyro(message.chat.id, file_path, caption=video_caption)
                    await message.answer(f"âœ… ØªÙ… Ø¥Ø±Ø³Ø§Ù„ ÙÙŠØ¯ÙŠÙˆ ÙƒØ¨ÙŠØ± Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Pyrogram: `{os.path.basename(file_path)}`")
                except Exception as e:
                    print(f"âŒ [Pyrogram Error] Failed to send large file: {e}")
                    await message.answer("âŒ Ø­ØµÙ„ Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„Ù…Ù„Ù Ø§Ù„ÙƒØ¨ÙŠØ± Ø¨ÙˆØ§Ø³Ø·Ø© Pyrogram.")
            else:
                while True:
                    try:
                        await message.answer_video(FSInputFile(file_path), caption=video_caption)
                        break
                    except TelegramRetryAfter as e:
                        print(f"â³ TelegramRetryAfter for video: {e.retry_after} seconds. Retrying...")
                        await asyncio.sleep(e.retry_after)
                    except Exception as e:
                        print(f"âŒ Error sending video {file_path}: {e}")
                        await message.answer("âŒ Ø­ØµÙ„ Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ.")
                        break # Ø§Ù„Ø®Ø±ÙˆØ¬ Ù…Ù† Ø­Ù„Ù‚Ø© Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© ÙÙŠ Ø­Ø§Ù„Ø© Ø®Ø·Ø£ Ø¢Ø®Ø± ØºÙŠØ± RetryAfter

            # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ÙÙŠØ¯ÙŠÙˆ Ø¨Ø¹Ø¯ Ø§Ù„Ø¥Ø±Ø³Ø§Ù„ ÙˆØ­Ø°Ù Ø§Ù„Ù…Ù„Ù Ø§Ù„Ù…Ø¤Ù‚Øª
            if os.path.exists(file_path):
                os.remove(file_path)
                print(f"ğŸ—‘ï¸ Removed file: {file_path}")
            if os.path.exists(dir_path) and not os.listdir(dir_path):
                os.rmdir(dir_path)
                print(f"ğŸ—‘ï¸ Removed empty directory: {dir_path}")

        album_accumulator[key]["video"] = [] # ØªÙØ±ÙŠØº Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„ÙÙŠØ¯ÙŠÙˆÙ‡Ø§Øª Ù„Ù‡Ø°Ù‡ Ø§Ù„Ø¯Ø±Ø¯Ø´Ø©

    except Exception as e:
        print(f"âŒ General error in reply_media for tweet {tweet_id}: {e}")
        if business_id is None:
            react = types.ReactionTypeEmoji(emoji="ğŸ‘")
            await message.react([react])
        await message.reply(f"Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ÙˆØ³Ø§Ø¦Ø· Ù„ØªØºØ±ÙŠØ¯Ø© {tweet_id} â˜¹ï¸: {e}")
    finally:
        # Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø¯Ù„ÙŠÙ„ Ø§Ù„Ø®Ø§Øµ Ø¨Ø§Ù„ØªØºØ±ÙŠØ¯Ø© Ø­ØªÙ‰ Ù„Ùˆ Ø­Ø¯Ø« Ø®Ø·Ø£
        if os.path.exists(tweet_dir) and not os.listdir(tweet_dir):
            os.rmdir(tweet_dir)
            print(f"ğŸ—‘ï¸ Final cleanup: Removed empty tweet directory {tweet_dir}")
        elif os.path.exists(tweet_dir):
            # Ø¥Ø°Ø§ Ù„Ù… ÙŠÙƒÙ† ÙØ§Ø±ØºÙ‹Ø§ØŒ ÙÙ‡Ø°Ø§ ÙŠØ¹Ù†ÙŠ Ø£Ù† Ù‡Ù†Ø§Ùƒ Ù…Ù„ÙØ§Øª Ù„Ù… ÙŠØªÙ… Ø­Ø°ÙÙ‡Ø§ (Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©)
            print(f"âš ï¸ Warning: Directory {tweet_dir} not empty after processing.")


async def process_chat_queue(chat_id):
    print(f"Starting processing queue for chat {chat_id}")
    while True:
        message = await chat_queues[chat_id].get()
        print(f"ğŸ”„ Processing message from queue for chat {chat_id}, message ID: {message.message_id}")
        try:
            business_id = message.business_connection_id
            if business_id is None:
                await message.react([types.ReactionTypeEmoji(emoji="ğŸ‘¨â€ğŸ’»")]) # Ø±Ø¯ ÙØ¹Ù„ Ù„Ù„Ù…Ø³ØªØ®Ø¯Ù…
            bot_url = f"t.me/{(await bot.get_me()).username}"
            
            # âœ… Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø¯Ø§Ù„Ø© Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø© ØºÙŠØ± Ø§Ù„Ù…ØªØ²Ø§Ù…Ù†Ø©
            tweet_ids = await extract_tweet_ids_async(message.text)
            
            if tweet_ids:
                if business_id is None:
                    await bot.send_chat_action(message.chat.id, "typing")
                for tweet_id in tweet_ids:
                    print(f"ğŸš€ Handling tweet ID: {tweet_id} in chat {chat_id}")
                    try:
                        media = scrape_media(tweet_id)
                        await reply_media(message, tweet_id, media, bot_url, business_id)
                    except Exception as e:
                        print(f"âŒ Error processing individual tweet {tweet_id}: {e}")
                        await message.reply(f"Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØªØºØ±ÙŠØ¯Ø© {tweet_id}: {e}")
            else:
                if business_id is None:
                    await message.react([types.ReactionTypeEmoji(emoji="ğŸ‘")])
                await message.answer("Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø±ÙˆØ§Ø¨Ø· X/Twitter ØµØ§Ù„Ø­Ø© ÙÙŠ Ø±Ø³Ø§Ù„ØªÙƒ.")
            
            # Ù…Ø­Ø§ÙˆÙ„Ø© Ø­Ø°Ù Ø§Ù„Ø±Ø³Ø§Ù„Ø© Ø§Ù„Ø£ØµÙ„ÙŠØ© Ø¨Ø¹Ø¯ Ø§Ù„Ø§Ù†ØªÙ‡Ø§Ø¡ Ù…Ù† Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©
            try:
                if business_id is None: # Ù„Ø§ ØªØ­Ø§ÙˆÙ„ Ø­Ø°Ù Ø±Ø³Ø§Ø¦Ù„ Ø§Ù„Ø£Ø¹Ù…Ø§Ù„ Ø¨Ø´ÙƒÙ„ Ø§ÙØªØ±Ø§Ø¶ÙŠ Ø¥Ø°Ø§ ÙƒØ§Ù† Ù‡Ø°Ø§ Ù‚Ø¯ ÙŠØ³Ø¨Ø¨ Ù…Ø´Ø§ÙƒÙ„
                    await message.delete()
                    print(f"ğŸ—‘ï¸ Deleted original message {message.message_id} in chat {chat_id}")
            except Exception as delete_error:
                print(f"âŒ Error deleting message {message.message_id} in chat {chat_id}: {delete_error}")
        finally:
            chat_queues[chat_id].task_done()
            print(f"âœ… Finished processing message from queue for chat {chat_id}.")

@router.message(F.text.regexp(r"(https?://(www\.)?(twitter|x)\.com/\S+|https?://t\.co/\S+)"))
@router.business_message(F.text.regexp(r"(https?://(www\.)?(twitter|x)\.com/\S+|https?://t\.co/\S+)"))
async def handle_tweet_links(message: types.Message):
    chat_id = message.chat.id
    if chat_id not in chat_queues:
        chat_queues[chat_id] = asyncio.Queue()
        # Ø§Ø¨Ø¯Ø£ Worker Ù„Ù„Ø¯Ø±Ø¯Ø´Ø© Ø¥Ø°Ø§ Ù„Ù… ÙŠÙƒÙ† Ù…ÙˆØ¬ÙˆØ¯Ù‹Ø§
        chat_workers[chat_id] = asyncio.create_task(process_chat_queue(chat_id))
        print(f"ğŸ†• Created new queue and worker for chat {chat_id}")
    else:
        print(f"â¡ï¸ Adding message to existing queue for chat {chat_id}")
    await chat_queues[chat_id].put(message)

# ØªØ£ÙƒØ¯ Ù…Ù† Ø£Ù† Ù‡Ø°Ù‡ Ø§Ù„ÙˆØ­Ø¯Ø© ÙŠØªÙ… Ø¥Ø¶Ø§ÙØªÙ‡Ø§ Ø¥Ù„Ù‰ Dispatcher Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ
# dp.include_router(router)
